{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6595c596-21db-4e15-8ff5-1df2e29820b7",
   "metadata": {},
   "source": [
    "![spotify_logo](../assets/Spotify_Logo_CMYK_Green.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8042cd1-b6e6-4ed3-b2ab-82a69f385b88",
   "metadata": {},
   "source": [
    "# Spotify Skip Prediction: Feature Engineering and Baseline Modelling\n",
    "Notebook: 4 of 7\n",
    "\n",
    "Author: Alex Thach - alcthach@gmail.com  \n",
    "BrainStation Data Science Capstone Project - Winter 2022  \n",
    "April 4, 2022\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a33113-ebde-4a71-baeb-17c5d367e042",
   "metadata": {},
   "source": [
    "# Recap:\n",
    "In the previous notebook I dived further into the data and completed some multivariate analysis. \n",
    "Some things to note from that notebook are:\n",
    "- Previous history of user interactions might be related the probability of the current track being skipped\n",
    "- Merged session logs and track features table successfully, written to a .csv file in the project directory\n",
    "- `'skip_2'` at best had weak correlations with other features in the dataset\n",
    "- Skip rate appeared to differ based on:\n",
    "    - Where in the sequence the song was located in a session\n",
    "    - Time-of-day\n",
    "    - Type of playlist song belonged to\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5088e938-db58-483d-b1ae-5ba9b2a0b776",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Purpose: \n",
    "The goal of this notebook employ some feature engineering and baseline modelling to gather an initial impression of the problem.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50803035-1919-44a4-b14e-a22a307d1039",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Summary/Highlights:\n",
    "- Some feature engineering was employed, including exploding of `'date'` column, and OneHotEncoding of categorical variables\n",
    "- Previous user interaction history appears to be a predictor of future skip outcomes, as indicated by improve classification accuracy when inputting data related to previous track interaction\n",
    "- Some features appear to be proxies for skip outcomes in previous tracks\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25584d40-489c-4461-bd86-0afcc2a8823a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframes in the global name space now include:\n",
      "session_logs_df\n",
      "track_features_df\n"
     ]
    }
   ],
   "source": [
    "# Runs setup script, imports, plotting settings, reads in raw data\n",
    "%run -i \"../scripts/at-setup.py\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b511e2dc-f900-4359-b019-1a0a7fbdcb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads in data\n",
    "main_df = pd.read_csv('../data/processed/merged.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5185ee6b-f562-4541-9651-414a0fa0fab6",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af71093c-4e9d-4e9c-8ec9-bdc82e0e7cac",
   "metadata": {},
   "source": [
    "Prior to any sort of modelling, it's good practice to take a look at the data types in the dataset. In other words, features that will be use to train a machine learning must be in a numeric form. I'll proceed to take a look at the dataset from the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45a1bfd5-d5a2-4061-a540-02a708eaf869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 167880 entries, 0 to 167879\n",
      "Data columns (total 46 columns):\n",
      " #   Column                           Non-Null Count   Dtype  \n",
      "---  ------                           --------------   -----  \n",
      " 0   session_id                       167880 non-null  object \n",
      " 1   session_position                 167880 non-null  int64  \n",
      " 2   session_length                   167880 non-null  int64  \n",
      " 3   skip_2                           167880 non-null  bool   \n",
      " 4   context_switch                   167880 non-null  int64  \n",
      " 5   no_pause_before_play             167880 non-null  int64  \n",
      " 6   short_pause_before_play          167880 non-null  int64  \n",
      " 7   long_pause_before_play           167880 non-null  int64  \n",
      " 8   hist_user_behavior_n_seekfwd     167880 non-null  int64  \n",
      " 9   hist_user_behavior_n_seekback    167880 non-null  int64  \n",
      " 10  hist_user_behavior_is_shuffle    167880 non-null  bool   \n",
      " 11  hour_of_day                      167880 non-null  int64  \n",
      " 12  date                             167880 non-null  object \n",
      " 13  premium                          167880 non-null  bool   \n",
      " 14  context_type                     167880 non-null  object \n",
      " 15  hist_user_behavior_reason_start  167880 non-null  object \n",
      " 16  hist_user_behavior_reason_end    167880 non-null  object \n",
      " 17  duration                         167880 non-null  float64\n",
      " 18  release_year                     167880 non-null  int64  \n",
      " 19  us_popularity_estimate           167880 non-null  float64\n",
      " 20  acousticness                     167880 non-null  float64\n",
      " 21  beat_strength                    167880 non-null  float64\n",
      " 22  bounciness                       167880 non-null  float64\n",
      " 23  danceability                     167880 non-null  float64\n",
      " 24  dyn_range_mean                   167880 non-null  float64\n",
      " 25  energy                           167880 non-null  float64\n",
      " 26  flatness                         167880 non-null  float64\n",
      " 27  instrumentalness                 167880 non-null  float64\n",
      " 28  key                              167880 non-null  int64  \n",
      " 29  liveness                         167880 non-null  float64\n",
      " 30  loudness                         167880 non-null  float64\n",
      " 31  mechanism                        167880 non-null  float64\n",
      " 32  mode                             167880 non-null  object \n",
      " 33  organism                         167880 non-null  float64\n",
      " 34  speechiness                      167880 non-null  float64\n",
      " 35  tempo                            167880 non-null  float64\n",
      " 36  time_signature                   167880 non-null  int64  \n",
      " 37  valence                          167880 non-null  float64\n",
      " 38  acoustic_vector_0                167880 non-null  float64\n",
      " 39  acoustic_vector_1                167880 non-null  float64\n",
      " 40  acoustic_vector_2                167880 non-null  float64\n",
      " 41  acoustic_vector_3                167880 non-null  float64\n",
      " 42  acoustic_vector_4                167880 non-null  float64\n",
      " 43  acoustic_vector_5                167880 non-null  float64\n",
      " 44  acoustic_vector_6                167880 non-null  float64\n",
      " 45  acoustic_vector_7                167880 non-null  float64\n",
      "dtypes: bool(3), float64(25), int64(12), object(6)\n",
      "memory usage: 56.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Gets the data types of the features in the dataset\n",
    "main_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81552b01-b814-4968-9670-319b8578252e",
   "metadata": {},
   "source": [
    "Most of the features of the dataset are numeric. However, there appear to be some that are not. I'll take a look at the non-numeric columns and see if I could transform them into numeric columns.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "539f30c5-c5d6-431b-b7bf-68122b38f140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session_id\n",
      "date\n",
      "context_type\n",
      "hist_user_behavior_reason_start\n",
      "hist_user_behavior_reason_end\n",
      "mode\n"
     ]
    }
   ],
   "source": [
    "# Gets columns that are non-numeric\n",
    "categorical_cols = [print(col) for col in main_df.columns if main_df[col].dtype == 'object']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c222da38-f8bd-4a9f-b66d-b119e8472e81",
   "metadata": {},
   "source": [
    "The output above shows which columns that are of type 'object' in the dataset. These are the columns I will look to convert to a numeric type if it's appropriate to.\n",
    "\n",
    "---\n",
    "## Initial Impressions\n",
    "\n",
    "- `'session_id'` is a column I would prefer to keep as is, it serves as a unique identifier for individual listening session. I would like to preserve that information in the dataset\n",
    "- `'date'` might be a column that I look to explode, or split into day, week, year\n",
    "- `'context_type'` indicates the type of playlist that a song belongs to, if you recall from the previous notebook, it appeared that there was a difference in skip rate across the different types of playlists, so it is worth numerizing this column\n",
    "- `'hist_user_behaviour_reason_start'` and ``'hist_user_behaviour_reason_end'` also appears to show differences in skip rate from the EDA in the previous notebook\n",
    "    - For that reason it's also worth converting to numeric\n",
    "- Finally, there is `'mode'` which indicates if a song is in a major or minor key\n",
    "- Conclusion: I will look to convert all the columns above to numeric, except for `'session_id'`, for which I will preserve this information in case there are any operations in which I will require this data in its original form\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d70e46e3-e491-4bbc-99bf-ece621b8d1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning variables\n",
    "X = main_df\n",
    "y = main_df['skip_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45d08c87-394e-459b-8590-5502b49cb39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Splitting into remainder and test sets\n",
    "# X_remainder, X_test, y_remainder, y_test = \\\n",
    "#     train_test_split(X, y, test_size = 0.2,\n",
    "#                      random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bceb0bb-3c44-4f94-aa81-a841ce54e4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Splitting the remainder into train and validation\n",
    "# X_train, X_validation, y_train, y_validation = \\\n",
    "#     train_test_split(X_remainder, y_remainder, test_size = 0.3,\n",
    "#                      random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d321f43-c39e-4d62-bf7c-8538a94eee1e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exploding the `'date'` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95fa5327-92d0-422d-b6c7-75c598ed9507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2018-07-15\n",
       "1    2018-07-15\n",
       "2    2018-07-15\n",
       "3    2018-07-15\n",
       "4    2018-07-15\n",
       "Name: date, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gets date column\n",
    "main_df['date'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba143a43-8d42-40c9-8d32-49246a422627",
   "metadata": {},
   "source": [
    "Granularizing the `'date'` columns unlocks more information about trends on various time scales. It provides more richness as compared to having only the individual day. Allows for possible study of trends on daily, monthly or yearly timeframes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5dc0b5-0045-4c4b-920d-23e82da8c479",
   "metadata": {},
   "source": [
    "This is accomplished by:  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa3c617-f22d-4732-a2b3-05ce53d1334c",
   "metadata": {},
   "source": [
    "Casting the `'date'` column as datetime, and exploding it into weekday, month, and year columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6c7cf84-5aaa-4fcc-9c6b-764d7f3a90e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casts 'date' column as datetime\n",
    "main_df['date'] = pd.to_datetime(session_logs_df['date'])\n",
    "\n",
    "# Explodes 'date' column into weekday, month, year, columns\n",
    "main_df['weekday'] = main_df['date'].dt.weekday\n",
    "main_df['month'] = main_df['date'].dt.month\n",
    "main_df['year'] = main_df['date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "977a24c2-200c-489e-a2dd-5c21ec4233dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>weekday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-07-15</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  weekday  month  year\n",
       "0 2018-07-15        6      7  2018"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 167880 entries, 0 to 167879\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count   Dtype         \n",
      "---  ------   --------------   -----         \n",
      " 0   date     167880 non-null  datetime64[ns]\n",
      " 1   weekday  167880 non-null  int64         \n",
      " 2   month    167880 non-null  int64         \n",
      " 3   year     167880 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(3)\n",
      "memory usage: 6.4 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sanity checks\n",
    "display(main_df[['date','weekday', 'month', 'year']].head(1))\n",
    "print(\"\")\n",
    "display(main_df[['date','weekday', 'month', 'year']].info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04f7bac-1c4a-4a15-9c91-25408f1bec08",
   "metadata": {},
   "source": [
    "## OneHotEncoding Categorical Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb9a7c1-d718-4d3d-8659-fc28effc0497",
   "metadata": {},
   "source": [
    "I will encode the categorical columns by employing `'ColumnTransformer'` and `'OneHotEncoder'`. By employing OneHotEncoding rather than dummy variables, I ensure that the model will be able to handle cases in which new categorical variables occur in a test set or in new incoming data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14548bbd-4de8-4745-930a-80ecace251a8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4c76003-1aae-4779-99ee-0ec872b7c5ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(transformers=[('enc', OneHotEncoder(),\n",
       "                                 ['context_type',\n",
       "                                  'hist_user_behavior_reason_start',\n",
       "                                  'hist_user_behavior_reason_end', 'mode'])])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creates the column transformations list and  columns to which to apply\n",
    "col_transforms = [('enc', OneHotEncoder(), ['context_type',\n",
    "                                                     'hist_user_behavior_reason_start',\n",
    "                                                     'hist_user_behavior_reason_end',\n",
    "                                                     'mode'])]\n",
    "\n",
    "# Creates the column transformer\n",
    "col_trans = ColumnTransformer(col_transforms)\n",
    "\n",
    "# Fits to X\n",
    "col_trans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53502286-dff0-4dcd-ae77-a127716b9300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applies the transformation\n",
    "transformed = col_trans.transform(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcddd440-3ce6-4e37-8170-c1d5ba874e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puts in a DataFrame\n",
    "transformed_df = pd.DataFrame(transformed.toarray(), columns=col_trans.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2043a8b4-0d48-43ce-a3ef-d2195ece8adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-assigns the transformed dataframe to X\n",
    "X = pd.concat([X, transformed_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58d42519-21d8-4cf5-ae5b-e9609cc4bea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['session_id', 'context_type', 'hist_user_behavior_reason_start', 'hist_user_behavior_reason_end', 'mode']\n"
     ]
    }
   ],
   "source": [
    "# List comprehension to figure out which features are categorical\n",
    "categorical_cols = ([col for col in X.columns if X[col].dtype == 'object'])\n",
    "print(categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7099fbf-3746-4552-93a2-4ec93b29fd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops OHE parent columns\n",
    "X = X.drop(columns=['context_type',\n",
    "                    'hist_user_behavior_reason_start',\n",
    "                    'hist_user_behavior_reason_end',\n",
    "                    'mode',\n",
    "                    'date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d502c6c1-d01e-40f2-98b8-c8c72bd72c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['session_id', 'session_position', 'session_length', 'skip_2',\n",
       "       'context_switch', 'no_pause_before_play', 'short_pause_before_play',\n",
       "       'long_pause_before_play', 'hist_user_behavior_n_seekfwd',\n",
       "       'hist_user_behavior_n_seekback', 'hist_user_behavior_is_shuffle',\n",
       "       'hour_of_day', 'premium', 'duration', 'release_year',\n",
       "       'us_popularity_estimate', 'acousticness', 'beat_strength', 'bounciness',\n",
       "       'danceability', 'dyn_range_mean', 'energy', 'flatness',\n",
       "       'instrumentalness', 'key', 'liveness', 'loudness', 'mechanism',\n",
       "       'organism', 'speechiness', 'tempo', 'time_signature', 'valence',\n",
       "       'acoustic_vector_0', 'acoustic_vector_1', 'acoustic_vector_2',\n",
       "       'acoustic_vector_3', 'acoustic_vector_4', 'acoustic_vector_5',\n",
       "       'acoustic_vector_6', 'acoustic_vector_7', 'weekday', 'month', 'year',\n",
       "       'enc__context_type_catalog', 'enc__context_type_charts',\n",
       "       'enc__context_type_editorial_playlist',\n",
       "       'enc__context_type_personalized_playlist', 'enc__context_type_radio',\n",
       "       'enc__context_type_user_collection',\n",
       "       'enc__hist_user_behavior_reason_start_appload',\n",
       "       'enc__hist_user_behavior_reason_start_backbtn',\n",
       "       'enc__hist_user_behavior_reason_start_clickrow',\n",
       "       'enc__hist_user_behavior_reason_start_endplay',\n",
       "       'enc__hist_user_behavior_reason_start_fwdbtn',\n",
       "       'enc__hist_user_behavior_reason_start_playbtn',\n",
       "       'enc__hist_user_behavior_reason_start_remote',\n",
       "       'enc__hist_user_behavior_reason_start_trackdone',\n",
       "       'enc__hist_user_behavior_reason_start_trackerror',\n",
       "       'enc__hist_user_behavior_reason_end_backbtn',\n",
       "       'enc__hist_user_behavior_reason_end_clickrow',\n",
       "       'enc__hist_user_behavior_reason_end_endplay',\n",
       "       'enc__hist_user_behavior_reason_end_fwdbtn',\n",
       "       'enc__hist_user_behavior_reason_end_logout',\n",
       "       'enc__hist_user_behavior_reason_end_remote',\n",
       "       'enc__hist_user_behavior_reason_end_trackdone', 'enc__mode_major',\n",
       "       'enc__mode_minor'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gets columns in X after transformations were completed\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "119cc54c-747e-4cdb-8dba-f96a03fd78f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['session_id']\n"
     ]
    }
   ],
   "source": [
    "# Checks again to see which columns are non-numeric, uses list comprehension\n",
    "categorical_cols = ([col for col in X.columns if X[col].dtype == 'object'])\n",
    "print(categorical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee07fc1-3e26-4a92-b590-90096a76da29",
   "metadata": {},
   "source": [
    "The only column that is of type 'object' is `'session_id'`. I now have a dataset that is ready to be used for some baseline modelling! But let's write the newly transformed dataset to a .csv first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bb975dc-66b4-4ca0-9173-0e052917453b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writes transformed dataset to .csv\n",
    "X.to_csv('../data/processed/features.csv', index_label=False)\n",
    "y.to_csv('../data/processed/target.csv', index_label=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607336aa-ce13-4a80-9a07-6685eb59a975",
   "metadata": {},
   "source": [
    "## Baseline Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fccb5bc-2c47-4595-aa97-a1a2327614f4",
   "metadata": {},
   "source": [
    "### Experiment 1: Logistic Regression with Date-exploded features, and OneHotEncoded categorical variables\n",
    "We'll start off by training a logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cda762a6-cf1b-4123-9248-2c1fe6a0e9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops 'skip_2' from the for the sake of this experiment\n",
    "X1 = X.drop(columns = ['skip_2', 'session_id'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ae31002-7a27-4047-b6fe-62c99bf50988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into remainder and test sets\n",
    "X1_remainder, X1_test, y1_remainder, y1_test = \\\n",
    "    train_test_split(X1, y, test_size = 0.2,\n",
    "                     random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a95f5e52-26e1-457b-8eb5-05b97873243d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the remainder into train and validation\n",
    "X1_train, X1_validation, y1_train, y1_validation = \\\n",
    "    train_test_split(X1_remainder, y1_remainder, test_size = 0.3,\n",
    "                     random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4feedce7-bb35-4728-a1e0-5b30de5710d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8696336637876015\n",
      "0.8673682120520203\n"
     ]
    }
   ],
   "source": [
    "# Note: This cell will take some time to run!\n",
    "# Instantiates Logit\n",
    "logit = LogisticRegression(max_iter=500, verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fits\n",
    "logit.fit(X1_train, y1_train)\n",
    "\n",
    "# Scores on train and validation\n",
    "print(logit.score(X1_train, y1_train))\n",
    "print(logit.score(X1_validation, y1_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dd619e-2f2e-47c6-bea8-c27563ebbbfa",
   "metadata": {},
   "source": [
    "The accuracy on this model is suspiciously high. Although we removed `'skip_2'` we might suspect some sort of data leakage elsewhere. Remember that I had mentioned that there are features that indicate how a track was skipped. In other words, `'enc__hist_user_behavior_reason_end'` might be embedding some hidden information about a track skipping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a0fa38d-9e8c-44c0-a782-31e39817dd20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['enc__hist_user_behavior_reason_end_backbtn',\n",
       "       'enc__hist_user_behavior_reason_end_clickrow',\n",
       "       'enc__hist_user_behavior_reason_end_endplay',\n",
       "       'enc__hist_user_behavior_reason_end_fwdbtn',\n",
       "       'enc__hist_user_behavior_reason_end_logout',\n",
       "       'enc__hist_user_behavior_reason_end_remote',\n",
       "       'enc__hist_user_behavior_reason_end_trackdone'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gets features that indicate how a track ended\n",
    "X.filter(like='reason_end').columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae8b833-243a-42cd-8bbd-b38931ebd036",
   "metadata": {},
   "source": [
    "I suspect that these columns allowed the model to look into the future. In other words, the model is seeing how the track ended. And it may be signalling whether the track was skipped or not skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cabe2319-51eb-4534-80e5-2e0644ed469a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops 'skip_2', 'session_id' , and end track features\n",
    "X2 = X.drop(columns = ['skip_2', 'session_id','enc__hist_user_behavior_reason_end_backbtn',\n",
    "       'enc__hist_user_behavior_reason_end_clickrow',\n",
    "       'enc__hist_user_behavior_reason_end_endplay',\n",
    "       'enc__hist_user_behavior_reason_end_fwdbtn',\n",
    "       'enc__hist_user_behavior_reason_end_logout',\n",
    "       'enc__hist_user_behavior_reason_end_remote',\n",
    "       'enc__hist_user_behavior_reason_end_trackdone'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "995fad70-4b99-4ced-934f-593f91b52136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into remainder and test sets\n",
    "X2_remainder, X2_test, y2_remainder, y2_test = \\\n",
    "    train_test_split(X2, y, test_size = 0.2,\n",
    "                     random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ac7dca1-3fab-47a3-b4d5-c36815df21d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the remainder into train and validation\n",
    "X2_train, X2_validation, y2_train, y2_validation = \\\n",
    "    train_test_split(X2_remainder, y2_remainder, test_size = 0.3,\n",
    "                     random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "290cc7b9-3f35-4e5f-a6a3-3d48cf675687",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7613422019259406\n"
     ]
    }
   ],
   "source": [
    "# Instantiates Logit\n",
    "logit2 = LogisticRegression(max_iter=500, verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fits\n",
    "logit2.fit(X2_train, y2_train)\n",
    "\n",
    "# Gets validation score\n",
    "print(logit2.score(X2_validation, y2_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42cb86d4-1880-40af-ba92-785bd7d0284d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7561353347629259"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gets test score\n",
    "logit2.score(X2_test, y2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d390766-e03c-4a2e-842b-40bfad12c48e",
   "metadata": {},
   "source": [
    "Based on the output above, the classfication accuracy has been reduced. Which confirms my suspicion of data leakage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "53291773-c1a9-4bf2-a0bc-198e3231cd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strongest Predictors of Track Skip, Yes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1.481308</td>\n",
       "      <td>enc__hist_user_behavior_reason_start_fwdbtn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.521965</td>\n",
       "      <td>enc__hist_user_behavior_reason_start_backbtn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.503234</td>\n",
       "      <td>short_pause_before_play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.308042</td>\n",
       "      <td>long_pause_before_play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.090590</td>\n",
       "      <td>enc__context_type_user_collection</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        coef                                       feature\n",
       "52  1.481308   enc__hist_user_behavior_reason_start_fwdbtn\n",
       "49  0.521965  enc__hist_user_behavior_reason_start_backbtn\n",
       "4   0.503234                       short_pause_before_play\n",
       "5   0.308042                        long_pause_before_play\n",
       "47  0.090590             enc__context_type_user_collection"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strongest Predictors of Track Skip, No\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.140239</td>\n",
       "      <td>premium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.147923</td>\n",
       "      <td>context_switch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.207280</td>\n",
       "      <td>hist_user_behavior_n_seekback</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>-0.277215</td>\n",
       "      <td>enc__hist_user_behavior_reason_start_clickrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>-1.729335</td>\n",
       "      <td>enc__hist_user_behavior_reason_start_trackdone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        coef                                         feature\n",
       "10 -0.140239                                         premium\n",
       "2  -0.147923                                  context_switch\n",
       "7  -0.207280                   hist_user_behavior_n_seekback\n",
       "50 -0.277215   enc__hist_user_behavior_reason_start_clickrow\n",
       "55 -1.729335  enc__hist_user_behavior_reason_start_trackdone"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gets coefficients from the model\n",
    "print(\"Strongest Predictors of Track Skip, Yes\")\n",
    "display(pd.DataFrame(list(zip(list(np.ravel(logit2.coef_)), logit2.feature_names_in_)), columns=['coef', 'feature']).sort_values(by='coef', ascending=False).head())\n",
    "print(\"Strongest Predictors of Track Skip, No\")\n",
    "display(pd.DataFrame(list(zip(list(np.ravel(logit2.coef_)), logit2.feature_names_in_)), columns=['coef', 'feature']).sort_values(by='coef', ascending=False).tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7797a69-6a1d-48ce-89fc-19d19be1a846",
   "metadata": {},
   "source": [
    "Based on the cell output above. Use of the forward button appears to be a strong predictor of a track being skipped. In contrast, if a current track starts because the previous song was played until the end, the current track is less likely to be skipped.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333fb6ca-75ad-4176-bc04-fc4ba5c29495",
   "metadata": {},
   "source": [
    "Let's see what happens if I withold information about how the song started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "967f96cd-33de-4fe7-844b-501a7c31ff5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops 'skip_2', 'session_id' , and end track features\n",
    "X3 = X.drop(columns = ['skip_2', 'session_id','enc__hist_user_behavior_reason_end_backbtn',\n",
    "                    'enc__hist_user_behavior_reason_end_clickrow',\n",
    "                    'enc__hist_user_behavior_reason_end_endplay',\n",
    "                    'enc__hist_user_behavior_reason_end_fwdbtn',\n",
    "                    'enc__hist_user_behavior_reason_end_logout',\n",
    "                    'enc__hist_user_behavior_reason_end_remote',\n",
    "                    'enc__hist_user_behavior_reason_end_trackdone',\n",
    "                    'enc__hist_user_behavior_reason_start_fwdbtn',\n",
    "                    'enc__hist_user_behavior_reason_start_trackdone'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146fec69-7d59-44a9-9759-436ef0736c70",
   "metadata": {},
   "source": [
    "By witholding some information about how the song started, I'm not letting the model know if the previous track was skipped or played in its entirety. In other words, if the song was started by pressing the forward button, the previous song was likely skipped. If the user arrived at the current song because the previous song was played entirely, then there was likely no skip leading up to the current track. I had suspected this since encountering the differences in skip rate when the current started due to pressing the forward button or the previous track being played until the end. It would appear that previous skip/play behaviour is somehow linked to skip outcomes in the preceding song. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ca8d936-f039-4382-a4c6-6191ff86a5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into remainder and test sets\n",
    "X3_remainder, X3_test, y3_remainder, y3_test = \\\n",
    "    train_test_split(X3, y, test_size = 0.2,\n",
    "                     random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b4886f59-6c47-4cbd-9e72-af2b350dce61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the remainder into train and validation\n",
    "X3_train, X3_validation, y3_train, y3_validation = \\\n",
    "    train_test_split(X3_remainder, y3_remainder, test_size = 0.3,\n",
    "                     random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c1efac54-075a-4112-9d0a-438af7233a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5878834508090937\n"
     ]
    }
   ],
   "source": [
    "# Note: This cell will take some time to run\n",
    "# Instantiates Logit\n",
    "logit3 = LogisticRegression(max_iter=500, verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fits\n",
    "logit3.fit(X3_train, y3_train)\n",
    "\n",
    "# Scores on train and validation\n",
    "# print(logit.score(X2_train, y2_train))\n",
    "print(logit3.score(X3_validation, y3_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8faeaba0-f7f0-46ab-b26a-7ff5e9659444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.580325232308792"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit3.score(X3_test, y3_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88abb79-48c3-4486-85d6-14fbf8f67a5a",
   "metadata": {},
   "source": [
    "My suspicion appears be confirmed based on the classification accuracy of this particular model. Previous user interaction, related to how the track ended, which also tells us if the previous song was skipped, appears to be an important predictor of future skip outcomes. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffc0975-961d-4d99-b2ec-e35b876a9cd0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Wrapping Up\n",
    "- In this notebook I managed to gather an initial impression of the problem \n",
    "- Some insights drawn from my exploratory data analysis appeared to have re-emerged during baseline modelling \n",
    "- I.E. Previous user interaction history being a predictor skip outcomes in the following track\n",
    "- At this point I have conduct a bit of feature engineering and baseline modelling\n",
    "- The second logit model employed, without `skip_2` and track end behaviours had a test score of about 76%, which outperforms a naive model which if guesses skip every single time would be right 52% of the time\n",
    "- In other words, the second logit model would guess about 7 songs correctly out of 10, whereas the naive model would guess roughly 5/10 correctly\n",
    "---\n",
    "# Next Steps\n",
    "- In the next notebook I will continue with feature engineering and will be employing more model experiments\n",
    "- To see if I can improve classification accuracy above our baseline Logit model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
